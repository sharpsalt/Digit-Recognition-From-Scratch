{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f9243ab-cdf6-4a7a-aab8-cff9096fec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0f2398-a825-4ac0-bc50-fd406e47e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_csv(path):\n",
    "    data = np.loadtxt(path, delimiter=',', skiprows=1)\n",
    "    X = data[:, 1:] / 255.0  # Normalize pixel values\n",
    "    y = data[:, 0].astype(int)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7ec386f-4f63-461f-b6ee-9f9c5cb2e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.2.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 7.1/11.1 MB 41.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 33.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 7.3/41.0 MB 35.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 11.5/41.0 MB 28.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 15.5/41.0 MB 24.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.7/41.0 MB 23.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 23.9/41.0 MB 22.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 28.0/41.0 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.5/41.0 MB 22.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/41.0 MB 22.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.5/41.0 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/41.0 MB 19.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 18.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a1d8841-8fc7-4999-85b9-79354904cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3599721-e1ce-43c6-a27e-e8f7cfd0681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (1.15.2)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\srija\\appdata\\roaming\\python\\python313\\site-packages (from scipy) (2.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d90de0-4215-45eb-9bbb-39d01f3b80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_mnist_csv('mnist_train.csv')\n",
    "X_test, y_test = load_mnist_csv('mnist_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c59b8b-d563-4d82-a664-573ff1aa8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes=10):\n",
    "    one_hot = np.zeros((y.size, num_classes))\n",
    "    one_hot[np.arange(y.size), y] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2ac4fc-ff6b-49cc-85b6-ff586ebe61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = one_hot_encode(y_train)\n",
    "y_test_encoded = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00984d5-ce0d-40e7-8b25-7fae77628658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "\n",
    "    W1 = np.random.randn(input_size, hidden_size) * np.sqrt(1. / input_size)\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    \n",
    "    W2 = np.random.randn(hidden_size, output_size) * np.sqrt(1. / hidden_size)\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb79480c-fced-4e8e-a728-3b7676153ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "\n",
    "W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a741ce5-2cc0-4d8e-824d-ff476df6c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))  # prevent overflow\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ec4bcc-34bb-4836-82fa-5945856a1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    \n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    \n",
    "    cache = (X, Z1, A1, Z2, A2)  # Save for backpropagation\n",
    "    return A2, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84873678-d27e-4a7c-aec0-657696f95287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(Y_pred, Y_true):\n",
    "    m = Y_true.shape[0]\n",
    "    epsilon = 1e-9  # prevent log(0)\n",
    "    loss = -np.sum(Y_true * np.log(Y_pred + epsilon)) / m\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29863060-2364-4c27-9b9f-3b73fcf1126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(Y_pred, Y_true):\n",
    "    predictions = np.argmax(Y_pred, axis=1)\n",
    "    labels = np.argmax(Y_true, axis=1)\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac97cd6-8e88-4b36-96b1-129de1e0e804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.3381, accuracy: 0.1248\n"
     ]
    }
   ],
   "source": [
    "Y_pred_train, _ = forward_pass(X_train, W1, b1, W2, b2)\n",
    "loss = compute_loss(Y_pred_train, y_train_encoded)\n",
    "acc = compute_accuracy(Y_pred_train, y_train_encoded)\n",
    "print(f\"Initial loss: {loss:.4f}, accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91520323-ea1f-43ff-adb3-324567cb10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(Z):\n",
    "    return Z > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7465e80-42b3-4b5e-976b-677aa5d20eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(Y_pred, Y_true, cache, W2):\n",
    "    X, Z1, A1, Z2, A2 = cache\n",
    "    m = Y_true.shape[0]\n",
    "\n",
    "    dZ2 = (Y_pred - Y_true) / m  # Gradient of loss w.r.t Z2\n",
    "    dW2 = np.dot(A1.T, dZ2)\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = np.dot(X.T, dZ1)\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfc3e8c7-a0f4-447a-8670-5d9a182f4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train_encoded, X_val, y_val_encoded,\n",
    "          epochs=10, batch_size=64, learning_rate=0.01):\n",
    "    \n",
    "    input_size = X_train.shape[1]\n",
    "    hidden_size = 128\n",
    "    output_size = 10\n",
    "\n",
    "    # Initialize weights\n",
    "    W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        permutation = np.random.permutation(X_train.shape[0])\n",
    "        X_train_shuffled = X_train[permutation]\n",
    "        y_train_shuffled = y_train_encoded[permutation]\n",
    "\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            X_batch = X_train_shuffled[i:i + batch_size]\n",
    "            y_batch = y_train_shuffled[i:i + batch_size]\n",
    "\n",
    "            Y_pred, cache = forward_pass(X_batch, W1, b1, W2, b2)\n",
    "            dW1, db1, dW2, db2 = backward_pass(Y_pred, y_batch, cache, W2)\n",
    "\n",
    "            # Gradient descent update\n",
    "            W1 -= learning_rate * dW1\n",
    "            b1 -= learning_rate * db1\n",
    "            W2 -= learning_rate * dW2\n",
    "            b2 -= learning_rate * db2\n",
    "\n",
    "        # Evaluate after each epoch\n",
    "        Y_pred_val, _ = forward_pass(X_val, W1, b1, W2, b2)\n",
    "        loss = compute_loss(Y_pred_val, y_val_encoded)\n",
    "        acc = compute_accuracy(Y_pred_val, y_val_encoded)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {loss:.4f}, Val Acc: {acc:.4f}\")\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19c77f62-afb7-4686-a3af-204157b52637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Val Loss: 0.5066, Val Acc: 0.8817\n",
      "Epoch 2/50 - Val Loss: 0.3763, Val Acc: 0.9012\n",
      "Epoch 3/50 - Val Loss: 0.3319, Val Acc: 0.9076\n",
      "Epoch 4/50 - Val Loss: 0.3073, Val Acc: 0.9142\n",
      "Epoch 5/50 - Val Loss: 0.2865, Val Acc: 0.9200\n",
      "Epoch 6/50 - Val Loss: 0.2738, Val Acc: 0.9227\n",
      "Epoch 7/50 - Val Loss: 0.2610, Val Acc: 0.9263\n",
      "Epoch 8/50 - Val Loss: 0.2498, Val Acc: 0.9300\n",
      "Epoch 9/50 - Val Loss: 0.2398, Val Acc: 0.9329\n",
      "Epoch 10/50 - Val Loss: 0.2315, Val Acc: 0.9354\n",
      "Epoch 11/50 - Val Loss: 0.2225, Val Acc: 0.9374\n",
      "Epoch 12/50 - Val Loss: 0.2151, Val Acc: 0.9386\n",
      "Epoch 13/50 - Val Loss: 0.2076, Val Acc: 0.9404\n",
      "Epoch 14/50 - Val Loss: 0.2005, Val Acc: 0.9437\n",
      "Epoch 15/50 - Val Loss: 0.1946, Val Acc: 0.9435\n",
      "Epoch 16/50 - Val Loss: 0.1891, Val Acc: 0.9453\n",
      "Epoch 17/50 - Val Loss: 0.1847, Val Acc: 0.9462\n",
      "Epoch 18/50 - Val Loss: 0.1785, Val Acc: 0.9492\n",
      "Epoch 19/50 - Val Loss: 0.1735, Val Acc: 0.9502\n",
      "Epoch 20/50 - Val Loss: 0.1697, Val Acc: 0.9506\n",
      "Epoch 21/50 - Val Loss: 0.1653, Val Acc: 0.9518\n",
      "Epoch 22/50 - Val Loss: 0.1608, Val Acc: 0.9527\n",
      "Epoch 23/50 - Val Loss: 0.1573, Val Acc: 0.9540\n",
      "Epoch 24/50 - Val Loss: 0.1538, Val Acc: 0.9545\n",
      "Epoch 25/50 - Val Loss: 0.1498, Val Acc: 0.9568\n",
      "Epoch 26/50 - Val Loss: 0.1469, Val Acc: 0.9568\n",
      "Epoch 27/50 - Val Loss: 0.1441, Val Acc: 0.9584\n",
      "Epoch 28/50 - Val Loss: 0.1406, Val Acc: 0.9584\n",
      "Epoch 29/50 - Val Loss: 0.1387, Val Acc: 0.9597\n",
      "Epoch 30/50 - Val Loss: 0.1352, Val Acc: 0.9609\n",
      "Epoch 31/50 - Val Loss: 0.1323, Val Acc: 0.9610\n",
      "Epoch 32/50 - Val Loss: 0.1302, Val Acc: 0.9618\n",
      "Epoch 33/50 - Val Loss: 0.1282, Val Acc: 0.9628\n",
      "Epoch 34/50 - Val Loss: 0.1262, Val Acc: 0.9623\n",
      "Epoch 35/50 - Val Loss: 0.1237, Val Acc: 0.9638\n",
      "Epoch 36/50 - Val Loss: 0.1231, Val Acc: 0.9637\n",
      "Epoch 37/50 - Val Loss: 0.1192, Val Acc: 0.9650\n",
      "Epoch 38/50 - Val Loss: 0.1170, Val Acc: 0.9656\n",
      "Epoch 39/50 - Val Loss: 0.1163, Val Acc: 0.9659\n",
      "Epoch 40/50 - Val Loss: 0.1148, Val Acc: 0.9664\n",
      "Epoch 41/50 - Val Loss: 0.1122, Val Acc: 0.9674\n",
      "Epoch 42/50 - Val Loss: 0.1121, Val Acc: 0.9666\n",
      "Epoch 43/50 - Val Loss: 0.1102, Val Acc: 0.9669\n",
      "Epoch 44/50 - Val Loss: 0.1088, Val Acc: 0.9679\n",
      "Epoch 45/50 - Val Loss: 0.1065, Val Acc: 0.9682\n",
      "Epoch 46/50 - Val Loss: 0.1051, Val Acc: 0.9682\n",
      "Epoch 47/50 - Val Loss: 0.1043, Val Acc: 0.9690\n",
      "Epoch 48/50 - Val Loss: 0.1033, Val Acc: 0.9693\n",
      "Epoch 49/50 - Val Loss: 0.1026, Val Acc: 0.9701\n",
      "Epoch 50/50 - Val Loss: 0.1010, Val Acc: 0.9710\n"
     ]
    }
   ],
   "source": [
    "trained_W1, trained_b1, trained_W2, trained_b2 = train(\n",
    "    X_train, y_train_encoded,\n",
    "    X_test, y_test_encoded,  # You can use test as val for now\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c365d539-4572-4b0e-a0cd-cfb80226b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.970997099709971\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test, _ = forward_pass(X_test, trained_W1, trained_b1, trained_W2, trained_b2)\n",
    "print(\"Final Test Accuracy:\", compute_accuracy(Y_pred_test, y_test_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b308a2ee-4c5e-4792-86c0-251e3af86c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 4\n",
      "True Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 5\n",
    "sample_image = X_test[sample_index].reshape(1, -1)  # shape (1, 784)\n",
    "true_label = np.argmax(y_test_encoded[sample_index])\n",
    "\n",
    "# Predict\n",
    "Y_pred_sample, _ = forward_pass(sample_image, trained_W1, trained_b1, trained_W2, trained_b2)\n",
    "predicted_label = np.argmax(Y_pred_sample)\n",
    "\n",
    "# Display result\n",
    "print(f\"Predicted Label: {predicted_label}\")\n",
    "print(f\"True Label: {true_label}\")\n",
    "\n",
    "# Visualize\n",
    "plt.imshow(sample_image.reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Predicted: {predicted_label}, Actual: {true_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac455b17-44a6-4276-a538-99edc310d46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b5281d-d833-4175-bca0-d436e2df9343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
